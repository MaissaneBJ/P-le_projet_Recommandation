{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de comparer la performance (basée sur la métrique RMSE) de nos algorithmes lorsqu'on prend des matrices aléatoires de même taille et de même rang et qu'on'change le nombre d'entrées révélées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des modules nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as alg\n",
    "from utilities import generate_low_rank, generate_entries\n",
    "from convex_optimization import test_convex\n",
    "from gradient_descent_script import generate_prediction_noprint, generate_M\n",
    "from clustering_method import complete_matrix\n",
    "from clean_altmin import predict_AltMin\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables et fonctions pour tester chaque algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100 #taille des matrices\n",
    "r=int(n**(1/5)) #rang des matrices (ce rang est considéré comme assez faible pour la méthode d'optimisation convexe)\n",
    "step=150 #pas sur le nombre d'entrées\n",
    "nb_iter=1 #nombre d'expériences pour chaque valeur du nombre d'entrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gradient=lambda A,omega: alg.norm(A-generate_prediction_noprint(A,omega,learning_rate=0.1))/A.size**0.5\n",
    "def test_alternating(A,omega):\n",
    "    M=generate_M(A,omega)\n",
    "    P=predict_AltMin(M,*A.shape)\n",
    "    return alg.norm(A-P)/P.size**0.5\n",
    "def test_clustering(A,omega): \n",
    "    n,p=A.shape\n",
    "    M=np.zeros((n,p))\n",
    "    for i,j in omega:\n",
    "        M[i,j]=A[i,j]\n",
    "    return alg.norm(A-complete_matrix(M))/A.size**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chacune de ces fonctions prend en entrée la matrice complète et l'ensemble omega des entrées révélées et retourne la RMSE de la prédiction de l'algorithme correspondant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traçage des courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:23<25:03, 83.53s/it]"
     ]
    }
   ],
   "source": [
    "nb_samples=np.arange(1,3000,step)\n",
    "RMSE_convex=np.ndarray(nb_samples.shape)\n",
    "RMSE_gradient=np.ndarray(nb_samples.shape)\n",
    "RMSE_alternating=np.ndarray(nb_samples.shape)\n",
    "RMSE_clustering=np.ndarray(nb_samples.shape)\n",
    "for p in tqdm(range(len(nb_samples))):\n",
    "    k=nb_samples[p] #nombre d'entrées\n",
    "    #listes contenant les valeurs de la RMSE obtenue pour chaque expérience\n",
    "    X_convex=np.ndarray(nb_iter)\n",
    "    X_gradient=np.ndarray(nb_iter)\n",
    "    X_alternating=np.ndarray(nb_iter)\n",
    "    X_clustering=np.ndarray(nb_iter)\n",
    "    for i in range(nb_iter):\n",
    "        omega=generate_entries(n,n,k)\n",
    "        A=generate_low_rank(n,n,r)\n",
    "        X_convex[i]=test_convex(A,omega)\n",
    "        X_gradient[i]=test_gradient(A,omega)\n",
    "        X_clustering[i]=test_clustering(A,omega)\n",
    "        X_alternating[i]=test_alternating(A,omega)\n",
    "    #On calcule la moyenne de la RMSE\n",
    "    RMSE_convex[p]=np.mean(X_convex)\n",
    "    RMSE_gradient[p]=np.mean(X_gradient)\n",
    "    RMSE_alternating[p]=np.mean(X_alternating)\n",
    "    RMSE_clustering[p]=np.mean(X_clustering)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nb_samples,RMSE_convex,label=\"Optimisation convexe\")\n",
    "plt.plot(nb_samples,RMSE_gradient,label=\"Descente du gradient\")\n",
    "plt.plot(nb_samples,RMSE_alternating,label=\"Minimisation alternée\")\n",
    "plt.plot(nb_samples,RMSE_clustering,label=\"Clustering\")\n",
    "plt.ylabel(\"RMSE moyen\")\n",
    "plt.xlabel(\"nombre d'entrées révélées\")\n",
    "plt.title(\"RMSE en fonction du nombre d'entrées révélées\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
